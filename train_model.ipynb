{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization,Conv2D,MaxPooling2D\n",
    "import os\n",
    "\n",
    "#Emotion_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "img_rows, img_cols = 48,48\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = 'C:/Users/Harshil/Downloads/archive (2)/images/train'\n",
    "validation_data_dir = 'C:/Users/Harshil/Downloads/archive (2)/images/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.4,\n",
    "    height_shift_range = 0.4,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator( rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode = 'grayscale',\n",
    "    target_size = (img_rows, img_cols),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    color_mode = 'grayscale',\n",
    "    target_size = (img_rows, img_cols),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 1\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer = 'he_normal', input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding = 'same', kernel_initializer = 'he_normal', input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(256, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3,3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'Emotion_model.h5',\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0,\n",
    "    patience = 3,\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.2,\n",
    "    patience = 3,\n",
    "    verbose = 1,\n",
    "    min_delta = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [earlystop, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 21476\n",
    "nb_validation_samples = 3006\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 2.2455 - accuracy: 0.1893\n",
      "Epoch 00001: val_loss improved from inf to 1.78145, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 293s 437ms/step - loss: 2.2455 - accuracy: 0.1893 - val_loss: 1.7814 - val_accuracy: 0.2618\n",
      "Epoch 2/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.8502 - accuracy: 0.2208\n",
      "Epoch 00002: val_loss improved from 1.78145 to 1.75919, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 229s 342ms/step - loss: 1.8502 - accuracy: 0.2208 - val_loss: 1.7592 - val_accuracy: 0.2702\n",
      "Epoch 3/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.8014 - accuracy: 0.2481\n",
      "Epoch 00003: val_loss improved from 1.75919 to 1.75477, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 223s 333ms/step - loss: 1.8014 - accuracy: 0.2481 - val_loss: 1.7548 - val_accuracy: 0.2685\n",
      "Epoch 4/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.7836 - accuracy: 0.2506\n",
      "Epoch 00004: val_loss improved from 1.75477 to 1.75403, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 220s 328ms/step - loss: 1.7836 - accuracy: 0.2506 - val_loss: 1.7540 - val_accuracy: 0.2567\n",
      "Epoch 5/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.7577 - accuracy: 0.2702\n",
      "Epoch 00005: val_loss improved from 1.75403 to 1.67855, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 219s 326ms/step - loss: 1.7577 - accuracy: 0.2702 - val_loss: 1.6785 - val_accuracy: 0.3293\n",
      "Epoch 6/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.7211 - accuracy: 0.2964\n",
      "Epoch 00006: val_loss did not improve from 1.67855\n",
      "671/671 [==============================] - 223s 332ms/step - loss: 1.7211 - accuracy: 0.2964 - val_loss: 1.7786 - val_accuracy: 0.3239\n",
      "Epoch 7/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.6604 - accuracy: 0.3362\n",
      "Epoch 00007: val_loss improved from 1.67855 to 1.47914, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 234s 348ms/step - loss: 1.6604 - accuracy: 0.3362 - val_loss: 1.4791 - val_accuracy: 0.4388\n",
      "Epoch 8/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.5906 - accuracy: 0.3722\n",
      "Epoch 00008: val_loss improved from 1.47914 to 1.37074, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 246s 366ms/step - loss: 1.5906 - accuracy: 0.3722 - val_loss: 1.3707 - val_accuracy: 0.4667\n",
      "Epoch 9/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.5476 - accuracy: 0.4009\n",
      "Epoch 00009: val_loss improved from 1.37074 to 1.33966, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 247s 368ms/step - loss: 1.5476 - accuracy: 0.4009 - val_loss: 1.3397 - val_accuracy: 0.5017\n",
      "Epoch 10/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.5073 - accuracy: 0.4142\n",
      "Epoch 00010: val_loss did not improve from 1.33966\n",
      "671/671 [==============================] - 246s 366ms/step - loss: 1.5073 - accuracy: 0.4142 - val_loss: 1.3535 - val_accuracy: 0.4758\n",
      "Epoch 11/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.4813 - accuracy: 0.4211\n",
      "Epoch 00011: val_loss improved from 1.33966 to 1.29638, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 242s 361ms/step - loss: 1.4813 - accuracy: 0.4211 - val_loss: 1.2964 - val_accuracy: 0.4943\n",
      "Epoch 12/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.4518 - accuracy: 0.4398\n",
      "Epoch 00012: val_loss improved from 1.29638 to 1.26594, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 239s 356ms/step - loss: 1.4518 - accuracy: 0.4398 - val_loss: 1.2659 - val_accuracy: 0.5094\n",
      "Epoch 13/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.4344 - accuracy: 0.4519\n",
      "Epoch 00013: val_loss improved from 1.26594 to 1.20237, saving model to Emotion_model.h5\n",
      "671/671 [==============================] - 257s 382ms/step - loss: 1.4344 - accuracy: 0.4519 - val_loss: 1.2024 - val_accuracy: 0.5349\n",
      "Epoch 14/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.4178 - accuracy: 0.4565\n",
      "Epoch 00014: val_loss did not improve from 1.20237\n",
      "671/671 [==============================] - 240s 358ms/step - loss: 1.4178 - accuracy: 0.4565 - val_loss: 1.2299 - val_accuracy: 0.5175\n",
      "Epoch 15/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.4069 - accuracy: 0.4632\n",
      "Epoch 00015: val_loss did not improve from 1.20237\n",
      "671/671 [==============================] - 236s 352ms/step - loss: 1.4069 - accuracy: 0.4632 - val_loss: 1.2326 - val_accuracy: 0.5192\n",
      "Epoch 16/25\n",
      "671/671 [==============================] - ETA: 0s - loss: 1.3867 - accuracy: 0.4686Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.20237\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "671/671 [==============================] - 228s 339ms/step - loss: 1.3867 - accuracy: 0.4686 - val_loss: 1.2452 - val_accuracy: 0.5353\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
